# ğŸ¤– AI-Powered Web-Searching Chat Assistant with Tool Calling

## ğŸŒŸ Overview
This project is an AI-powered chat assistant built with Streamlit and Langchain. The assistant can engage in natural conversations, search the web using DuckDuckGo, and provide informative responses while maintaining conversational context. It utilizes Langchain's tool-calling functionality to integrate external tools like web search seamlessly.

## âœ¨ Features
- ğŸ’¬ **Conversational AI:** Powered by the `mistral-nemo:latest` model from Ollama.
- ğŸŒ **Web Search with Tool Calling:** Integrates DuckDuckGo search using Langchainâ€™s tool-calling mechanism for real-time information.
- ğŸ¨ **Customizable Settings:** Adjustable response creativity with a temperature slider.
- ğŸ—‚ï¸ **Conversation History:** Maintains chat history until cleared.

## ğŸ› ï¸ Installation

### ğŸ“‹ Prerequisites
Ensure you have the following installed:
- ğŸ Python 3.9 or later
- ğŸ§  Ollama installed and running locally

### ğŸ“¦ Dependencies
```bash
pip install streamlit langchain-core langchain-ollama langchain-community duckduckgo-search
```

## ğŸš€ Usage
1. ğŸ§© Clone this repository:
```bash
git clone https://github.com/your-repo/ai-chat-assistant.git
cd ai-chat-assistant
```

2. â–¶ï¸ Run the Streamlit app:
```bash
streamlit run app.py
```

3. ğŸŒ Open the app in your browser at [http://localhost:8501](http://localhost:8501).

## ğŸ—‚ï¸ Application Structure
- ğŸ’¬ **Main Chat Interface:** Users can input messages, and the assistant responds.
- âš™ï¸ **Sidebar:** Allows configuration of the model's temperature and clearing chat history.

## âš™ï¸ Configuration
- ğŸ¨ **Model Temperature:** Controls response creativity (0.0 = more focused, 1.0 = more creative).
- ğŸŒ **Web Search with Tool Calling:** Automatically triggered when external information is needed.

## ğŸ§© Code Highlights
- ğŸ“ **System Prompt:** Guides the AI to be helpful, concise, and context-aware.
- ğŸ”§ **Tool Integration:** Uses `web_search` as a callable tool within Langchain.
- ğŸ› ï¸ **Tool Calling:** Langchainâ€™s tool-calling functionality enables the assistant to invoke external tools dynamically.
- ğŸ’¾ **Session State:** Manages messages, LLM instances, and tool bindings.

## ğŸ› ï¸ Customization
- ğŸ§  **Change the LLM Model:** Modify the `ChatOllama` initialization in `initialize_session_state()`.
- ğŸ§© **Add More Tools:** Define additional tools using `@tool` decorators.

## ğŸ§¹ Troubleshooting
- âœ… Ensure Ollama is running locally.
- ğŸ“¦ Verify that all dependencies are correctly installed.
- ğŸŒ Check your internet connection for web search functionality.
- ğŸ› ï¸ Ensure that the tool-calling mechanism in Langchain is correctly configured.

## ğŸ“œ License
This project is licensed under the Apache2.0 License.

## ğŸ‘¤ Author
Sasidharan B

## ğŸ™ Acknowledgments
- ğŸ¨ Streamlit for the user interface
- ğŸ§  Langchain for LLM and tool integration
- ğŸŒ DuckDuckGo for web search
